# Dropbox/Drive |@CoinBase

* Whimsical: [link](https://whimsical.com/dropbox-Pxo3WmfgEvHq4MXhYeme84)

#### #1. Requirement Gathering ======================================

#### 1.1 Functional Requirements

* upload/download
* automatic synchronization between devices
* history of updates(versioning)
* should support offline editing

#### 1.2 NonFunctional Requirements - Usage Patterns(read heavy/CAP tradeoffs)

* Cross device consistency: all the data should be in sync
* ACID-ity is required
* Read == Write

#### 1.3 Out of Scope

*

#### #2. Back-of-the-envelope estimation ============================

#### 2.1 Scale of System

* Total users = 500M
* DAU = 100M
* each user connects from 3 different devices
* 1 user has 200 files/photos
  * \=> Total files = 100B
* 10 requests per user per day
  * \=> 100M requests/day
* High write & read

#### 2.2 Storage size estimation

* avg file size = 1MB
  * \=> total space reqd = 1MB\*100B = **100 PB**

#### 4.2 DBs choices(NoSQL/SQL)

* **Metadata DB:**
  * has to be \*\*ACID \*\*(for conflict resolve)
  * \=> SQL

#### #5. Draw 'Basic HLD'=============================================

#### #6. Detailed HLD ================================================

* **How versioning works?✅**
  * **OPTION#1**: keep a separate copy in cloud after every change.
    * \*\*Issue with this approach: \*\*in a 2GB file, even for a single char change; we'll have to keep a full 2GB file in cloud. => Huge wastage of resources
  * \*\*OPTION#2: \*\*break down the file into **1000 chunks** (2MB each)
    * On first upload: all \*\*1000 chunks \*\*& **1 metadata file** are uploaded to cloud
    * On subsequent changes; lets say only\*\* chunk#1 & chunk#10\*\*1 were change; so **only these 2 chunks** & **metadata file** gets uploaded in **version2.0**
    * \*\*Another adv: \*\*the upload script can work in \*\*parallel to upload \*\*each chunk individually.
* **Client:**
  * is configured to keep track of files inside the folder
  * Client Application monitors the workspace folder on the user’s machine and syncs all files/folders in it with the remote Cloud Storage
  * operations for the client:
    1. Upload and download files.
    2. Detect file changes in the workspace folder.
    3. Handle conflict due to offline or concurrent updates.
  * Based on the above considerations, we can divide our client into following **four parts**:
  * **Watcher:**
    * gets **notified** when a **new file is added** to folder
    * Watcher passes this info (alog with the meta-data of changes) to **chunker & indexer**
  * **Chunker**
    * breaks down the new file into chunks
    * calculate **hash of each chunk**
    * uploads all the chunks to **Cloud(S3)**
    * **passes** this info to **indexer**:
      * **Url** it got after uploading to S3
      * **hash** of each chunk
  * **Indexer**
    * \*\*receives \*\*this info from **chunker:**
      * **Url** it got after uploading to S3
      * **hash** of each chunk
    * \*\*updates \*\*this info in \*\*internal DB \*\*against that file for which those **hash** belong to
    * \*\*indexer \*\*also passes this info to \*\*sync service \*\*via \*\*messaging queue \*\*for:
      * **conflict resolution(** updates could happen from multiple **Clients**, no?**)**
      * store metadata if device is **offline**
* **Sync Service:**
  * sends back the updated info of this file to all the **clients**
  * \*\*Indexer \*\*receives this info & updates corresponding files in the **folder**
  * \*\*=> this is how files remain in sync across all devices ✅ \*\*

![](../../.gitbook/assets/screenshot-2021-08-28-at-7.17.52-pm.png)

![](../../.gitbook/assets/screenshot-2021-08-28-at-7.17.59-pm.png)

